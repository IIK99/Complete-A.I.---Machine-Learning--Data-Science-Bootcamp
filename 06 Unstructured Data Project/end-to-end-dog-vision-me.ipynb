{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üê∂ Using Transfer Learning and TensorFlow 2.0 to Classify Different Dog Breeds\n",
    "\n",
    "Who's that doggy in the window?\n",
    "\n",
    "Dogs are incredible. But have you ever been sitting at a cafe, seen a dog and not known what breed it is? I have. And then someone says, \"it's an English Terrier\" and you think, how did they know that?\n",
    "\n",
    "In this project we're going to be using machine learning to help us identify different breeds of dogs.\n",
    "\n",
    "To do this, we'll be using data from the Kaggle dog breed identification competition. It consists of a collection of 10,000+ labelled images of 120 different dog breeds.\n",
    "\n",
    "This kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different breeds of dog. If we were only trying to classify dogs versus cats, it would be called binary classification (one thing versus another).\n",
    "\n",
    "Multi-class image classification is an important problem because it's the same kind of technology Tesla uses in their self-driving cars or Airbnb uses in atuomatically adding information to their listings.\n",
    "\n",
    "Since the most important step in a deep learng problem is getting the data ready (turning it into numbers), that's what we're going to start with.\n",
    "\n",
    "We're going to go through the following TensorFlow/Deep Learning workflow:\n",
    "\n",
    " 1. Get data ready (download from Kaggle, store, import).\n",
    " 2. Prepare the data (preprocessing, the 3 sets, X & y).\n",
    " 3. Choose and fit/train a model (TensorFlow Hub, tf.keras.applications, TensorBoard, EarlyStopping).\n",
    " 4. Evaluating a model (making predictions, comparing them with the ground truth labels).\n",
    " 5. Improve the model through experimentation (start with 1000 images, make sure it works, increase the number of images).\n",
    " 6. Save, sharing and reloading your model (once you're happy with the results).\n",
    "\n",
    "For preprocessing our data, we're going to use TensorFlow 2.x. The whole premise here is to get our data into Tensors (arrays of numbers which can be run on GPUs) and then allow a machine learning model to find patterns between them.\n",
    "\n",
    "For our machine learning model, we're going to be using a pretrained deep learning model from TensorFlow Hub.\n",
    "\n",
    "The process of using a pretrained model and adapting it to your own problem is called transfer learning. We do this because rather than train our own model from scratch (could be timely and expensive), we leverage the patterns of another model which has been trained to classify images.\n",
    "\n",
    "### Getting our workspace ready\n",
    "\n",
    "Before we get started, since we'll be using TensorFlow 2.x and TensorFlow Hub (TensorFlow Hub), let's import them.\n",
    "\n",
    "**NOTE:** Don't run the cell below if you're already using TF 2.x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TF 2.X\n",
    "try:\n",
    "    # %tensorflow_version only exist in colab\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "After restarting the runtime and rerunning the cell above, it tells us TensorFlow 2.x is selected.\n",
    "\n",
    "**NOTE:** You may not need to do the above steps in the future when TensorFlow 2.x becomes the default in Colab.\n",
    "\n",
    "Let's rerun some import statements. And check whether or not we're using a GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\IIK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "TF version:  2.16.2\n",
      "TensorFlow version:  0.16.1\n",
      "GPU:  not available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "\n",
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"TensorFlow version: \", tf_hub.__version__)\n",
    "\n",
    "# check for GPU\n",
    "print(\n",
    "    \"GPU: \",\n",
    "    \"available (YES!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
