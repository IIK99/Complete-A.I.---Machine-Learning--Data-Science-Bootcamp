{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://gist.github.com/IIK99/f76a7d1435c4cc9b75e66125d2bab70a#file-end-to-end-dog-vision-gdrive-ipynb",
      "authorship_tag": "ABX9TyNgFyOhHU4IVJS3VTHUrJhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IIK99/Complete-A.I.---Machine-Learning--Data-Science-Bootcamp/blob/main/06%20Unstructured%20Data%20Project/end_to_end_dog_vision_gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Using Transfer Learning and TensorFlow 2.0 to Classify Different Dog Breeds\n",
        "\n",
        "Who's that doggy in the window?\n",
        "\n",
        "Dogs are incredible. But have you ever been sitting at a cafe, seen a dog and not known what breed it is? I have. And then someone says, \"it's an English Terrier\" and you think, how did they know that?\n",
        "\n",
        "In this project we're going to be using machine learning to help us identify different breeds of dogs.\n",
        "\n",
        "To do this, we'll be using data from the Kaggle dog breed identification competition. It consists of a collection of 10,000+ labelled images of 120 different dog breeds.\n",
        "\n",
        "This kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different breeds of dog. If we were only trying to classify dogs versus cats, it would be called binary classification (one thing versus another).\n",
        "\n",
        "Multi-class image classification is an important problem because it's the same kind of technology Tesla uses in their self-driving cars or Airbnb uses in atuomatically adding information to their listings.\n",
        "\n",
        "Since the most important step in a deep learng problem is getting the data ready (turning it into numbers), that's what we're going to start with.\n",
        "\n",
        "We're going to go through the following TensorFlow/Deep Learning workflow:\n",
        "\n",
        "   1. Get data ready (download from Kaggle, store, import).\n",
        "   2. Prepare the data (preprocessing, the 3 sets, X & y).\n",
        "   3. Choose and fit/train a model (TensorFlow Hub, tf.keras.applications, TensorBoard, EarlyStopping).\n",
        "   4. Evaluating a model (making predictions, comparing them with the ground truth labels).\n",
        "   5. Improve the model through experimentation (start with 1000 images, make sure it works, increase the number of images).\n",
        "   6. Save, sharing and reloading your model (once you're happy with the results).\n",
        "\n",
        "For preprocessing our data, we're going to use TensorFlow 2.x. The whole premise here is to get our data into Tensors (arrays of numbers which can be run on GPUs) and then allow a machine learning model to find patterns between them.\n",
        "\n",
        "For our machine learning model, we're going to be using a pretrained deep learning model from TensorFlow Hub.\n",
        "\n",
        "The process of using a pretrained model and adapting it to your own problem is called transfer learning. We do this because rather than train our own model from scratch (could be timely and expensive), we leverage the patterns of another model which has been trained to classify images.\n",
        "\n",
        "### Getting our workspace ready\n",
        "\n",
        "Before we get started, since we'll be using TensorFlow 2.x and TensorFlow Hub (TensorFlow Hub), let's import them.\n",
        "\n",
        "NOTE: Don't run the cell below if you're already using TF 2.x.\n"
      ],
      "metadata": {
        "id": "uW7lW5-irIwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TF 2.x\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1egDPuVrMwD",
        "outputId": "6982a2a1-1aa3-46c6-ced5-9774542fcf1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "After restarting the runtime and rerunning the cell above, it tells us TensorFlow 2.x is selected.\n",
        "\n",
        "**NOTE:** You may not need to do the above steps in the future when TensorFlow 2.x becomes the default in Colab.\n",
        "\n",
        "Let's rerun some import statements. And check whether or not we're using a GPU.\n"
      ],
      "metadata": {
        "id": "_MdGXxqbr4L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU\n",
        "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAzFbRxJrwSb",
        "outputId": "30015b06-6141-46a2-a908-3795a412fd99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.15.0\n",
            "Hub version: 0.16.1\n",
            "GPU available (YESS!!!!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You might be wondering what a GPU is or why we need one. The short story is, a GPU is a computer chip which is faster at doing numerical computing. And since machine learning is all about finding patterns in numbers, that's what we're after.\n",
        "\n",
        "Running this for the first time in Colab will let us know there's no GPU available.\n",
        "\n",
        "This is because by default Colab runs on a computer located on Google's servers which doesn't have a GPU attached to it.\n",
        "\n",
        "But we can fix this going to runtime and then changing the runtime type:\n",
        "\n",
        "    1. Go to Runtime.\n",
        "    2. Click \"Change runtime type\".\n",
        "    3. Where it says \"Hardware accelerator\", choose \"GPU\" (don't worry about TPU for now but feel free to research them).\n",
        "    4. Click save.\n",
        "    5. The runtime will be restarted to activate the new hardware, so you'll have to rerun the above cells.\n",
        "    6. If the steps have worked you should see a print out saying \"GPU available\".\n",
        "\n",
        "If you want an example of how much a GPU speeds up computing, Google Colab have a demonstration notebook available.\n",
        "\n",
        "### Getting data ready\n",
        "\n",
        "Since much of machine learning is getting your data ready to be used with a machine learning model, we'll take extra care getting it setup.\n",
        "\n",
        "There are a few ways we could do this. Many of them are detailed in the Google Colab notebook on I/O (input and output).\n",
        "\n",
        "And because the data we're using is hosted on Kaggle, we could even use the Kaggle API.\n",
        "\n",
        "This is great but what if the data you want to use wasn't on Kaggle?\n",
        "\n",
        "One method is to upload it to your Google Drive, mount your drive in this notebook and import the file.\n"
      ],
      "metadata": {
        "id": "W7JO7zMDsZW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-SAZIRfsD7L",
        "outputId": "ace1a910-3a33-4feb-927c-bf1f23e23e16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
        "\n",
        "Enter your authorization code:\n",
        "路路路路路路路路路路\n",
        "Mounted at /content/drive\n",
        "\n",
        "Following the prompts from the cell above, if everything worked, you should see a \"drive\" folder available under the Files tab.\n",
        "\n",
        "This means we'll be able to access files in our Google Drive right in this notebook.\n",
        "\n",
        "For this project, I've downloaded the data from Kaggle and uploaded it to my Google Drive as a .zip file under the folder \"Data\".\n",
        "\n",
        "To access it, we'll have to unzip it.\n",
        "\n",
        "Note: Running the cell below for the first time could take a while (a couple of minutes is normal). After you've run it once and got the data in your Google Drive, you don't need to run it again.\n",
        "\n",
        "Note 2: Wherever you see something like drive/My Drive/Data/ you will need to change it to wherever you are storing your files for this project. The first place you'll have to change it is the cell below.\n",
        "\n"
      ],
      "metadata": {
        "id": "xU6VU6wrt8_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v989bDrvswuW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}